{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ongoing-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import image_prep as prep\n",
    "import image_utils as utils\n",
    "import finetune_model as finetune\n",
    "from image_gradient import RGBgradients\n",
    "import activation_maximization as am\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "images_path = '%s/architecture' % data_path\n",
    "originals_path = '%s/orig_sized' % data_path\n",
    "tensors_path = '%s/image_tensors' % data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-liquid",
   "metadata": {},
   "source": [
    "## Resize and Crop the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sizes = prep.get_image_sizes(images_path)\n",
    "\n",
    "prep.resize_and_crop(im_sizes, originals_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-monaco",
   "metadata": {},
   "source": [
    "## Create image tensor files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2idx = prep.get_lab_to_idx(images_path)\n",
    "\n",
    "images_to_tensors(images_path, tensors_path, lab2idx, im_size=128, max_per_file=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-copying",
   "metadata": {},
   "source": [
    "## Download the pretrained InceptionV3 model and finetune on architecture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.quantization.inception_v3(pretrained=True, aux_logits=False)\n",
    "\n",
    "#replace the classification layer\n",
    "model.fc = nn.Linear(2048, len(lab2idx))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'inception_model'\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model, train_losses, cv_losses = finetune.finetune_model(model, tensor_path, model_path, \n",
    "                                                         lab2idx, device, batch_size=8, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot train loss\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_losses, color='blue')\n",
    "plt.legend(['Train Loss'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot cv loss\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(cv_losses, color='orange')\n",
    "plt.legend(['CV Loss'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-companion",
   "metadata": {},
   "source": [
    "## Load best model and maximize activations of various neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('%s/model.pt' % model_path))\n",
    "model.eval()\n",
    "\n",
    "#freeze model params\n",
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "#view the layer choices\n",
    "for n,p in model.named_parameters():\n",
    "    if '.conv.' in n:\n",
    "        print(p.size(), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will register a forward hook to get the output of the layers\n",
    "activation = {} \n",
    "\n",
    "def create_hook(name):\n",
    "    def hook(m, i, o):\n",
    "        # copy the output of the given layer\n",
    "        activation[name] = o\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a layer\n",
    "layer_name = 'Mixed_7a.branch3x3_1'\n",
    "\n",
    "#create a hook for the layer\n",
    "model.Mixed_7a.branch3x3_1.conv.register_forward_hook(create_hook(layer_name))\n",
    "\n",
    "#choose a neuron\n",
    "unit_idx = 5\n",
    "\n",
    "#activations will be stored here, make sure it's clear\n",
    "activation = {}\n",
    "\n",
    "#create the pixel gradient calculating network\n",
    "gradLayer = RGBgradients()\n",
    "\n",
    "#call maximize_activation_with_scaling\n",
    "am.maximize_activation_with_scaling(model, gradLayer, activation, layer_name, unit_idx,\n",
    "                                    upscaling_steps=20, upscaling_factor=1.05, \n",
    "                                    optim_steps=40, optim_lr=0.4, act_wt=0.5,\n",
    "                                    model_name='inception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call maximize_activation_octaves\n",
    "am.maximize_activation_octaves(model, gradLayer, activation, layer_name, unit_idx, im_size=(256,256), \n",
    "                               num_octaves=4, octave_scale=1.4, optim_steps=20, optim_lr=0.4, act_wt=0.75,\n",
    "                               model_name='inception')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-professor",
   "metadata": {},
   "source": [
    "## Compare to original InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model = models.quantization.inception_v3(pretrained=True, aux_logits=False)\n",
    "\n",
    "orig_model.eval()\n",
    "\n",
    "#freeze model params\n",
    "for param in orig_model.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a layer\n",
    "layer_name = 'Mixed_7a.branch3x3_1'\n",
    "\n",
    "#create a hook for the layer\n",
    "orig_model.Mixed_7a.branch3x3_1.conv.register_forward_hook(create_hook(layer_name))\n",
    "\n",
    "#choose a neuron\n",
    "unit_idx = 5\n",
    "\n",
    "#activations will be stored here, make sure it's clear\n",
    "activation = {}\n",
    "\n",
    "#create the pixel gradient calculating network\n",
    "gradLayer = RGBgradients()\n",
    "\n",
    "#call maximize_activation_with_scaling\n",
    "am.maximize_activation_with_scaling(orig_model, gradLayer, activation, layer_name, unit_idx,\n",
    "                                    upscaling_steps=20, upscaling_factor=1.05, \n",
    "                                    optim_steps=40, optim_lr=0.4, act_wt=0.5,\n",
    "                                    model_name='inception')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
